{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In this notebook, I will create classify model using TF-IDF algorithm for vectoring text and Random Forest, Native Bayes, SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy version: 2.1.4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Spacy version: {spacy.__version__}\")\n",
    "\n",
    "nlp_spacy = spacy.load('en_core_web_sm')\n",
    "\n",
    "def read_volcabulary(filename):\n",
    "    volcabulary = []\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            word, count = line.strip().split(',')\n",
    "            volcabulary.append(word.strip())\n",
    "    \n",
    "    return np.array(volcabulary)\n",
    "            \n",
    "VOCABULARY = read_volcabulary('corpus/vocabulary.txt')\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    #text = correct_spelling(text)\n",
    "    \n",
    "    doc = nlp_spacy(text)\n",
    "    \n",
    "    clean_bag_words = []\n",
    "    for token in doc:\n",
    "        if not (token.like_url or token.is_punct or token.is_space):\n",
    "            if token.is_currency:\n",
    "                clean_bag_words.append('_currency_')\n",
    "            elif token.ent_type_ == 'ORDINAL':\n",
    "                clean_bag_words.append('_ordinal_')\n",
    "            elif token.ent_type_ == 'TIME':\n",
    "                clean_bag_words.append('_time_')\n",
    "            elif token.ent_type_ == 'QUANTITY':\n",
    "                clean_bag_words.append('_quantity_')\n",
    "            else:\n",
    "                if token.lemma_ in VOCABULARY:\n",
    "                    clean_bag_words.append(token.lemma_)\n",
    "    \n",
    "    return clean_bag_words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['year' '_currency_' 'new' 'people' 'time' 'win' 'good' 'game' '_time_'\n",
      " 'film' 'world' 'government' 'play' 'go' 'come' 'work' '_ordinal_'\n",
      " 'company' 'take' 'firm']\n"
     ]
    }
   ],
   "source": [
    "print(VOCABULARY[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>CleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "      <td>['worldcom', 'boss', 'launch', 'defence', 'law...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "      <td>['german', 'business', 'confidence', 'slide', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "      <td>['bbc', 'poll', 'indicate', 'economic', 'gloom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "      <td>['lifestyle', 'govern', 'mobile', 'choice', 'f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "      <td>['enron', 'boss', '_currency_', 'payout', 'eig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category  \\\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...  business   \n",
       "1        154  german business confidence slides german busin...  business   \n",
       "2       1101  bbc poll indicates economic gloom citizens in ...  business   \n",
       "3       1976  lifestyle  governs mobile choice  faster  bett...      tech   \n",
       "4        917  enron bosses in $168m payout eighteen former e...  business   \n",
       "\n",
       "                                           CleanText  \n",
       "0  ['worldcom', 'boss', 'launch', 'defence', 'law...  \n",
       "1  ['german', 'business', 'confidence', 'slide', ...  \n",
       "2  ['bbc', 'poll', 'indicate', 'economic', 'gloom...  \n",
       "3  ['lifestyle', 'govern', 'mobile', 'choice', 'f...  \n",
       "4  ['enron', 'boss', '_currency_', 'payout', 'eig...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read trainning set and test set\n",
    "import pandas as pd\n",
    "\n",
    "trainning_set = pd.read_csv('corpus/clean_training_set.csv')\n",
    "test_set = pd.read_csv('dataset/BBC News Test.csv')\n",
    "\n",
    "trainning_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1018</td>\n",
       "      <td>qpr keeper day heads for preston queens park r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1319</td>\n",
       "      <td>software watching while you work software that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1138</td>\n",
       "      <td>d arcy injury adds to ireland woe gordon d arc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459</td>\n",
       "      <td>india s reliance family feud heats up the ongo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>boro suffer morrison injury blow middlesbrough...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text\n",
       "0       1018  qpr keeper day heads for preston queens park r...\n",
       "1       1319  software watching while you work software that...\n",
       "2       1138  d arcy injury adds to ireland woe gordon d arc...\n",
       "3        459  india s reliance family feud heats up the ongo...\n",
       "4       1020  boro suffer morrison injury blow middlesbrough..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing Text feature on test set\n",
    "#from tqdm.contrib.concurrent import thread_map\n",
    "#test_set['CleanText'] = thread_map(text_preprocessing, test_set['Text'])\n",
    "test_set = pd.read_csv('corpus/clean_test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_set['CleanText'] = test_set.CleanText.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving test_set\n",
    "#test_set.to_csv('corpus/clean_test_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1018</td>\n",
       "      <td>qpr keeper day heads for preston queens park r...</td>\n",
       "      <td>['qpr', 'keeper', 'day', 'head', 'preston', 'q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1319</td>\n",
       "      <td>software watching while you work software that...</td>\n",
       "      <td>['software', 'watch', '-PRON-', 'work', 'softw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1138</td>\n",
       "      <td>d arcy injury adds to ireland woe gordon d arc...</td>\n",
       "      <td>['arcy', 'injury', 'add', 'ireland', 'woe', 'g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459</td>\n",
       "      <td>india s reliance family feud heats up the ongo...</td>\n",
       "      <td>['india', 'reliance', 'family', 'feud', 'heat'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>boro suffer morrison injury blow middlesbrough...</td>\n",
       "      <td>['boro', 'suffer', 'morrison', 'injury', 'blow...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  \\\n",
       "0       1018  qpr keeper day heads for preston queens park r...   \n",
       "1       1319  software watching while you work software that...   \n",
       "2       1138  d arcy injury adds to ireland woe gordon d arc...   \n",
       "3        459  india s reliance family feud heats up the ongo...   \n",
       "4       1020  boro suffer morrison injury blow middlesbrough...   \n",
       "\n",
       "                                           CleanText  \n",
       "0  ['qpr', 'keeper', 'day', 'head', 'preston', 'q...  \n",
       "1  ['software', 'watch', '-PRON-', 'work', 'softw...  \n",
       "2  ['arcy', 'injury', 'add', 'ireland', 'woe', 'g...  \n",
       "3  ['india', 'reliance', 'family', 'feud', 'heat'...  \n",
       "4  ['boro', 'suffer', 'morrison', 'injury', 'blow...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>CleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>1923</td>\n",
       "      <td>eu to probe alitalia  state aid  the european ...</td>\n",
       "      <td>['probe', 'state', 'aid', 'european', 'commiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>373</td>\n",
       "      <td>u2 to play at grammy awards show irish rock ba...</td>\n",
       "      <td>['play', 'grammy', 'award', 'show', 'irish', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>1704</td>\n",
       "      <td>sport betting rules in spotlight a group of mp...</td>\n",
       "      <td>['sport', 'bet', 'rule', 'in', 'spotlight', 'g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>206</td>\n",
       "      <td>alfa romeos  to get gm engines  fiat is to sto...</td>\n",
       "      <td>['alfa', 'get', 'engine', 'fiat', 'stop', 'mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>471</td>\n",
       "      <td>citizenship event for 18s touted citizenship c...</td>\n",
       "      <td>['citizenship', 'event', 'tout', 'citizenship'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ArticleId                                               Text  \\\n",
       "730       1923  eu to probe alitalia  state aid  the european ...   \n",
       "731        373  u2 to play at grammy awards show irish rock ba...   \n",
       "732       1704  sport betting rules in spotlight a group of mp...   \n",
       "733        206  alfa romeos  to get gm engines  fiat is to sto...   \n",
       "734        471  citizenship event for 18s touted citizenship c...   \n",
       "\n",
       "                                             CleanText  \n",
       "730  ['probe', 'state', 'aid', 'european', 'commiss...  \n",
       "731  ['play', 'grammy', 'award', 'show', 'irish', '...  \n",
       "732  ['sport', 'bet', 'rule', 'in', 'spotlight', 'g...  \n",
       "733  ['alfa', 'get', 'engine', 'fiat', 'stop', 'mak...  \n",
       "734  ['citizenship', 'event', 'tout', 'citizenship'...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1490, 208)\n",
      "(735, 208)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#Vectorzing training set\n",
    "vectorizer = TfidfVectorizer(min_df=0.1, max_df=0.95)\n",
    "\n",
    "trainning_vector = vectorizer.fit_transform(trainning_set.CleanText).toarray()\n",
    "test_vector = vectorizer.transform(test_set.CleanText.values).toarray()\n",
    "print(trainning_vector.shape)\n",
    "print(test_vector.shape)\n",
    "\n",
    "print(type(trainning_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1490,)\n"
     ]
    }
   ],
   "source": [
    "#Init label encoder for news category feature\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "#Encode target, save to varible y\n",
    "y = encoder.fit_transform(trainning_set['Category'].values)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import  GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Evalution Model\n",
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "#CV splitrun model 10x with 70/20 split intentionally leaving out 10%\n",
    "cv_split = ShuffleSplit(n_splits = 5, test_size = .2,\n",
    "                        train_size = .7, random_state = 0)\n",
    "\n",
    "param_grids = [\n",
    "    #Random Forest\n",
    "    {'n_estimators': [100, 150, 250],\n",
    "     'criterion': ['gini', 'entropy']},\n",
    "\n",
    "    #GausianNB\n",
    "    {},\n",
    "\n",
    "    #SVC\n",
    "    {'C': [1, 10, 100],\n",
    "     'gamma': [0.01, 0.1, 0.001]},\n",
    "\n",
    "]\n",
    "\n",
    "MLA = [\n",
    "    RandomForestClassifier(),\n",
    "    GaussianNB(),\n",
    "    SVC(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 51.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import multiprocessing\n",
    "MAX_WORKER = multiprocessing.cpu_count() - 2\n",
    "\n",
    "report = pd.DataFrame()\n",
    "scoring = {'f1': 'f1_macro', 'precision': 'precision_macro', 'recall':'recall_macro'}\n",
    "\n",
    "row = 0\n",
    "for mla, param in zip(MLA, param_grids):\n",
    "    gscv = GridSearchCV(mla, param, cv = cv_split, return_train_score=True, n_jobs=MAX_WORKER, \n",
    "                        scoring=scoring, refit='f1', error_score='raise')\n",
    "    gscv.fit(trainning_vector,y)\n",
    "    \n",
    "    best_index = gscv.best_index_\n",
    "    \n",
    "    report.loc[row, 'algorithm'] = gscv.best_estimator_.__class__.__name__ + \"_TF_IDF_ONE_GRAM\"\n",
    "    report.loc[row, 'best_params'] = str(gscv.best_params_)\n",
    "    report.loc[row, 'f1_train'] = gscv.cv_results_['mean_train_f1'][best_index]\n",
    "    report.loc[row, 'f1_test'] = gscv.cv_results_['mean_test_f1'][best_index]\n",
    "    report.loc[row, 'recall_train'] = gscv.cv_results_['mean_train_recall'][best_index]\n",
    "    report.loc[row, 'recall_test'] = gscv.cv_results_['mean_test_recall'][best_index]\n",
    "    report.loc[row, 'precision_train'] = gscv.cv_results_['mean_train_precision'][best_index]\n",
    "    report.loc[row, 'precision_test'] = gscv.cv_results_['mean_test_precision'][best_index]\n",
    "    report.loc[row, 'fit_time'] = gscv.cv_results_['mean_fit_time'][best_index]\n",
    "    \n",
    "    \n",
    "    \n",
    "    row+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>best_params</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier_TF_IDF_ONE_GRAM</td>\n",
       "      <td>{'criterion': 'gini', 'n_estimators': 250}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.911843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910633</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914503</td>\n",
       "      <td>1.661590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GaussianNB_TF_IDF_ONE_GRAM</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.931458</td>\n",
       "      <td>0.858537</td>\n",
       "      <td>0.931203</td>\n",
       "      <td>0.859601</td>\n",
       "      <td>0.933053</td>\n",
       "      <td>0.861169</td>\n",
       "      <td>0.013115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC_TF_IDF_ONE_GRAM</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1}</td>\n",
       "      <td>0.986628</td>\n",
       "      <td>0.900158</td>\n",
       "      <td>0.986545</td>\n",
       "      <td>0.900327</td>\n",
       "      <td>0.986740</td>\n",
       "      <td>0.902152</td>\n",
       "      <td>0.262039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                algorithm  \\\n",
       "0  RandomForestClassifier_TF_IDF_ONE_GRAM   \n",
       "1              GaussianNB_TF_IDF_ONE_GRAM   \n",
       "2                     SVC_TF_IDF_ONE_GRAM   \n",
       "\n",
       "                                  best_params  f1_train   f1_test  \\\n",
       "0  {'criterion': 'gini', 'n_estimators': 250}  1.000000  0.911843   \n",
       "1                                          {}  0.931458  0.858537   \n",
       "2                     {'C': 10, 'gamma': 0.1}  0.986628  0.900158   \n",
       "\n",
       "   recall_train  recall_test  precision_train  precision_test  fit_time  \n",
       "0      1.000000     0.910633         1.000000        0.914503  1.661590  \n",
       "1      0.931203     0.859601         0.933053        0.861169  0.013115  \n",
       "2      0.986545     0.900327         0.986740        0.902152  0.262039  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are a sign of over-fitting on Random Forest and SVC\n",
    "\n",
    "- In general, all three model giving a high score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling using N-Gramm model + TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uni-Gram + 2-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1490, 2615)\n",
      "(735, 2615)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#Vectorzing training set\n",
    "vectorizer = TfidfVectorizer(min_df=0.01, max_df=0.95, ngram_range=(1,2))\n",
    "\n",
    "trainning_vector = vectorizer.fit_transform(trainning_set.CleanText).toarray()\n",
    "test_vector = vectorizer.transform(test_set.CleanText.values).toarray()\n",
    "print(trainning_vector.shape)\n",
    "print(test_vector.shape)\n",
    "\n",
    "print(type(trainning_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 50s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>best_params</th>\n",
       "      <th>f1_train</th>\n",
       "      <th>f1_test</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>recall_test</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>precision_test</th>\n",
       "      <th>fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier_TF_IDF_ONE_GRAM</td>\n",
       "      <td>{'criterion': 'gini', 'n_estimators': 250}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.911843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910633</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914503</td>\n",
       "      <td>1.661590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GaussianNB_TF_IDF_ONE_GRAM</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.931458</td>\n",
       "      <td>0.858537</td>\n",
       "      <td>0.931203</td>\n",
       "      <td>0.859601</td>\n",
       "      <td>0.933053</td>\n",
       "      <td>0.861169</td>\n",
       "      <td>0.013115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC_TF_IDF_ONE_GRAM</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1}</td>\n",
       "      <td>0.986628</td>\n",
       "      <td>0.900158</td>\n",
       "      <td>0.986545</td>\n",
       "      <td>0.900327</td>\n",
       "      <td>0.986740</td>\n",
       "      <td>0.902152</td>\n",
       "      <td>0.262039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier_TF_IDF_ONE_TWO_GRAM</td>\n",
       "      <td>{'criterion': 'entropy', 'n_estimators': 150}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950623</td>\n",
       "      <td>2.689887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GaussianNB_TF_IDF_ONE_TWO_GRAM</td>\n",
       "      <td>{}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.901938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.905434</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903421</td>\n",
       "      <td>0.193932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC_TF_IDF_ONE_TWO_GRAM</td>\n",
       "      <td>{'C': 10, 'gamma': 0.1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970559</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.970600</td>\n",
       "      <td>6.497143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    algorithm  \\\n",
       "0      RandomForestClassifier_TF_IDF_ONE_GRAM   \n",
       "1                  GaussianNB_TF_IDF_ONE_GRAM   \n",
       "2                         SVC_TF_IDF_ONE_GRAM   \n",
       "3  RandomForestClassifier_TF_IDF_ONE_TWO_GRAM   \n",
       "4              GaussianNB_TF_IDF_ONE_TWO_GRAM   \n",
       "5                     SVC_TF_IDF_ONE_TWO_GRAM   \n",
       "\n",
       "                                     best_params  f1_train   f1_test  \\\n",
       "0     {'criterion': 'gini', 'n_estimators': 250}  1.000000  0.911843   \n",
       "1                                             {}  0.931458  0.858537   \n",
       "2                        {'C': 10, 'gamma': 0.1}  0.986628  0.900158   \n",
       "3  {'criterion': 'entropy', 'n_estimators': 150}  1.000000  0.947797   \n",
       "4                                             {}  1.000000  0.901938   \n",
       "5                        {'C': 10, 'gamma': 0.1}  1.000000  0.970375   \n",
       "\n",
       "   recall_train  recall_test  precision_train  precision_test  fit_time  \n",
       "0      1.000000     0.910633         1.000000        0.914503  1.661590  \n",
       "1      0.931203     0.859601         0.933053        0.861169  0.013115  \n",
       "2      0.986545     0.900327         0.986740        0.902152  0.262039  \n",
       "3      1.000000     0.946281         1.000000        0.950623  2.689887  \n",
       "4      1.000000     0.905434         1.000000        0.903421  0.193932  \n",
       "5      1.000000     0.970559         1.000000        0.970600  6.497143  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "scoring = {'f1': 'f1_macro', 'precision': 'precision_macro', 'recall':'recall_macro'}\n",
    "\n",
    "for mla, param in zip(MLA, param_grids):\n",
    "    gscv = GridSearchCV(mla, param, cv = cv_split, return_train_score=True, n_jobs=MAX_WORKER, \n",
    "                        scoring=scoring, refit='f1', error_score='raise')\n",
    "    gscv.fit(trainning_vector,y)\n",
    "    \n",
    "    best_index = gscv.best_index_\n",
    "    \n",
    "    report.loc[row, 'algorithm'] = gscv.best_estimator_.__class__.__name__ + \"_TF_IDF_ONE_TWO_GRAM\"\n",
    "    report.loc[row, 'best_params'] = str(gscv.best_params_)\n",
    "    report.loc[row, 'f1_train'] = gscv.cv_results_['mean_train_f1'][best_index]\n",
    "    report.loc[row, 'f1_test'] = gscv.cv_results_['mean_test_f1'][best_index]\n",
    "    report.loc[row, 'recall_train'] = gscv.cv_results_['mean_train_recall'][best_index]\n",
    "    report.loc[row, 'recall_test'] = gscv.cv_results_['mean_test_recall'][best_index]\n",
    "    report.loc[row, 'precision_train'] = gscv.cv_results_['mean_train_precision'][best_index]\n",
    "    report.loc[row, 'precision_test'] = gscv.cv_results_['mean_test_precision'][best_index]\n",
    "    report.loc[row, 'fit_time'] = gscv.cv_results_['mean_fit_time'][best_index]\n",
    "    \n",
    "    row+=1\n",
    "    \n",
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overall score was increasing on average 5% \n",
    "- SVC has best performance with Two-Gram model\n",
    "- The fit time was dramatically rising\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save report\n",
    "report.to_csv('report_training.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "- Best performance model: SVC_TF_IDF_ONE_TWO_GRAM (Support Vector Machine + Two - Gram model + TF-IDF)\n",
    "- Using simple machine algorithm, did not apply BERT, Word2Vec or neural network, but overall score above 90%, best score is 97% on metric f1\n",
    "- Next time try with Word2Vec model to see if there are a better performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "299cc0f12f7d41819069429ffe373621fa25f2d2daa3da5f840bd97d4c8cb810"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
